---
---
@inproceedings{Fei_2024_ICRA_Real2Sim,
  author = {Liang*, Xiao and LIU*, Fei and Zhang, Yutong and Li, Yuelei and Lin, Shan and Yip, Michael},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Real-to-Sim Deformable Object Manipulation: Optimizing Physics Models with Residual Mappings for Robotic Surgery},
  ABSTRACT={Accurate deformable object manipulation (DOM) is essential for achieving autonomy in robotic surgery, where soft tissues are being displaced, stretched, and dissected. Many DOM methods can be powered by simulation, which ensures realistic deformation by adhering to the governing physical constraints and allowing for model prediction and control. However, real soft objects in robotic surgery, such as membranes and soft tissues, have complex, anisotropic physical parameters that a simulation with simple initialization from cameras may not fully capture. To use the simulation techniques in real surgical tasks, the "real-to-sim" gap needs to be properly compensated. In this work, we propose an online, adaptive parameter tuning approach for simulation optimization that (1) bridges the real-to-sim gap between a physics simulation and observations obtained 3D perceptions through estimating a residual mapping and (2) optimizes its stiffness parameters online. Our method ensures a small residual gap between the simulation and observation and improves the simulation's predictive capabilities. The effectiveness of the proposed mechanism is evaluated in the manipulation of both a thin-shell and volumetric tissue, representative of most tissue scenarios. This work contributes to the advancement of simulation-based deformable tissue manipulation and holds potential for improving surgical autonomy.},
  year = {2024},
  honor = {Under review},
  html={https://arxiv.org/abs/2309.11656},
  img = {/assets/img/publication_preview/Fei_2024_ICRA_Real2Sim.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2024_ICRA_Cloth,
  author = {Zhang*, Yutong and LIU*, Fei and Liang, Xiao and Yip, Michael},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Achieving Autonomous Cloth Manipulation with Optimal Control via Differentiable Physics-Aware Regularization and Safety Constraints},
  ABSTRACT={Cloth manipulation is a category of deformable object manipulation of great interest to the robotics community, from applications of automated laundry-folding and home organizing and cleaning to textiles and flexible manufacturing. Despite the desire for automated cloth manipulation, the thin-shell dynamics and under-actuation nature of cloth present significant challenges for robots to effectively interact with them. Many recent works omit explicit modeling in favor of learning-based methods that may yield control policies directly. However, these methods require large training sets that must be collected and curated. In this regard, we create a framework for differentiable modeling of cloth dynamics leveraging an Extended Position-based Dynamics (XPBD) algorithm. Together with the desired control objective, physics-aware regularization terms are designed for better results, including trajectory smoothness and elastic potential energy. In addition, safety constraints, such as avoiding obstacles, can be specified using signed distance functions (SDFs). We formulate the cloth manipulation task with safety constraints as a constrained optimization problem, which can be effectively solved by mainstream gradient-based optimizers thanks to the end-to-end differentiability of our framework. Finally, we assess the proposed framework for manipulation tasks with various safety thresholds and demonstrate the feasibility of result trajectories on a surgical robot. The effects of the regularization terms are analyzed in an additional ablation study.}, 
  year = {2024},
  honor = {Under review},
  html={https://arxiv.org/abs/2309.11655},
  img = {/assets/img/publication_preview/Fei_2024_ICRA_Cloth.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2024_ICRA_SuPerPM,
  author = {Lin, Shan and Miao, Albert and Alabiad, Ali and LIU, Fei and Wang, Kaiyuan and Lu, Jingpei and Richter, Florian and Yip, Michael},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {SuPerPM: A Large Deformation-Robust Surgical Perception Framework Based on Deep Point Matching Learned from Physical Constrained Simulation Data},
  ABSTRACT={Manipulation of tissue with surgical tools often results in large deformations that current methods in tracking and reconstructing algorithms have not effectively addressed. A major source of tracking errors during large deformations stems from wrong data association between observed sensor measurements with previously tracked scene. To mitigate this issue, we present a surgical perception framework, SuPerPM, that leverages learning-based non-rigid point cloud matching for data association, thus accommodating larger deformations. The learning models typically require training data with ground truth point cloud correspondences, which is challenging or even impractical to collect in surgical environments. Thus, for tuning the learning model, we gather endoscopic data of soft tissue being manipulated by a surgical robot and then establish correspondences between point clouds at different time points to serve as ground truth. This was achieved by employing a position-based dynamics (PBD) simulation to ensure that the correspondences adhered to physical constraints. The proposed framework is demonstrated on several challenging surgical datasets that are characterized by large deformations, achieving superior performance over state-of-the-art surgical scene tracking algorithms.},
  year = {2024},
  honor = {Under review},
  html={https://arxiv.org/abs/2309.13863},
  img = {/assets/img/publication_preview/Fei_2024_ICRA_SuPerPM.png},
  abbr = {conference},
  color = {color_conf},
}

@article{Fei_2023_SuEntong,
  doi = {10.1109/LRA.2023.3264766},
  html = {https://ieeexplore.ieee.org/document/10093017},
  author = {LIU*, Fei and Su*, Entong and Lu, Jingpei and Li, Mingen and Yip, Michael C.},
  ABSTRACT={Robot manipulation of rope-like objects is an interesting problem that has some critical applications, such as autonomous robotic suturing. Solving for and controlling rope is difficult due to the complexity of rope physics and the challenge of building fast and accurate models of deformable materials. While more data-driven approaches have become more popular for finding controllers that learn to do a single task, there is still a strong motivation for a model-based method that could be used to solve a large variety of optimization problems. Towards this end, we introduced compliant, position-based dynamics (XPBD) to model rope-like objects. Using geometric constraints, the model can represent the coupling of shear/stretch and bend/twist effects. Of crucial importance is that our formulation is differentiable, which can solve parameter estimation problems and improve the matching of rope physics to real-life scenarios (i.e., the real-to-sim problem). For the generality of rope-like objects, two different solvers are proposed to handle the inextensible and extensible effects of varied material stiffness for the rope. We demonstrate our framework's robustness and accuracy on real-to-sim experimental setups using the Baxter robot and the da Vinci research kit (DVRK). Our work leads to a new path for robotic manipulation of the deformable rope-like object taking advantage of the ready-to-use gradients.},
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Robotic Manipulation of Deformable Rope-like Objects Using Differentiable Compliant Position-based Dynamics},
  journal = {IEEE Robotics and Automation (RAL)},
  website = {https://entongsu.github.io/differential_rope-github.io/},
  year = {2023},
  abbr = {journal},
  color = {color_jour},
  img = {/assets/img/publication_preview/Fei_2022_SuEntong.png},
}

@article{Fei_2023_Xiao,
  author={Liang, Xiao and Lin, Shan and LIU, Fei and Schreiber, Dimitri and Yip, Michael C.},
  journal={IEEE Transactions on Biomedical Engineering (TBME)}, 
  title={ORRN: An ODE-based Recursive Registration Network for Deformable Respiratory Motion Estimation with Lung 4DCT Images},
  ABSTRACT={Deformable Image Registration (DIR) plays a significant role in quantifying deformation in medical data. Recent Deep Learning methods have shown promising accuracy and speedup for registering a pair of medical images. However, in 4D (3D + time) medical data, organ motion, such as respiratory motion and heart beating, can not be effectively modeled by pair-wise methods as they were optimized for image pairs but did not consider the organ motion patterns necessary when considering 4D data. This paper presents ORRN, an Ordinary Differential Equations (ODE)-based recursive image registration network. Our network learns to estimate time-varying voxel velocities for an ODE that models deformation in 4D image data. It adopts a recursive registration strategy to progressively estimate a deformation field through ODE integration of voxel velocities. We evaluate the proposed method on two publicly available lung 4DCT datasets, DIRLab and CREATIS, for two tasks: 1) registering all images to the extreme inhale image for 3D+t deformation tracking and 2) registering extreme exhale to inhale phase images. Our method outperforms other learning-based methods in both tasks, producing the smallest Target Registration Error of 1.24mm and 1.26mm, respectively. Additionally, it produces less than 0.001\% unrealistic image folding, and the computation speed is less than 1 second for each CT volume. ORRN demonstrates promising registration accuracy, deformation plausibility, and computation efficiency on group-wise and pair-wise registration tasks. It has significant implications in enabling fast and accurate respiratory motion estimation for treatment planning in radiation therapy or robot motion planning in thoracic needle insertion.},
  html = {https://ieeexplore.ieee.org/document/10144816}, 
  year={2023},
  keywords={},
  abbr = {journal},
  color = {color_jour},
  img = {/assets/img/publication_preview/Fei_2022_TBME.png},
}

@inproceedings{Fei_2023_ICRA_Jingpei,
  author = {Lu*, Jingpei and LIU*, Fei and Girerd, Cédric and Yip, Michael},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Image-based Pose Estimation and Shape Reconstruction for Robot Manipulators and Soft, Continuum Robots via Differentiable Rendering},
  ABSTRACT={State estimation from measured data is crucial for robotic applications as autonomous systems rely on sensors to capture the motion and localize in the 3D world. Among sensors that are designed for measuring a robot's pose, or for soft robots, their shape, vision sensors are favorable because they are information-rich, easy to set up, and cost-effective. With recent advancements in computer vision, deep learning-based methods no longer require markers for identifying feature points on the robot. However, learning-based methods are data-hungry and hence not suitable for soft and prototyping robots, as building such bench-marking datasets is usually infeasible. In this work, we achieve image-based robot pose estimation and shape reconstruction from camera images. Our method requires no precise robot meshes, but rather utilizes a differentiable renderer and primitive shapes. It hence can be applied to robots for which CAD models might not be available or are crude. Our parameter estimation pipeline is fully differentiable. The robot shape and pose are estimated iteratively by back-propagating the image loss to update the parameters. We demonstrate that our method of using geometrical shape primitives can achieve high accuracy in shape reconstruction for a soft continuum robot and pose estimation for a robot manipulator.},
  year = {2023},
  html={https://drive.google.com/file/d/1uVHnPBrp7bVKCLTqHECVVuatH8BOv2_g/view?usp=share_link},
  img = {/assets/img/publication_preview/Fei_2022_ICRA_Jingpei.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2023_ICRA_Neelay,
  doi = {10.48550/ARXIV.2209.13657},
  html = {https://arxiv.org/abs/2209.13657},
  author = {Joglekar, Neelay and LIU, Fei and Orosco, Ryan and Yip, Michael},
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Suture Thread Spline Reconstruction from Endoscopic Images for Robotic Surgery with Reliability-driven Keypoint Detection},
  booktitle = {2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  year = {2023},
  abstract = {Automating the process of manipulating and delivering sutures during robotic surgery is a prominent problem at the frontier of surgical robotics, as automating this task can significantly reduce surgeons' fatigue during tele-operated surgery and allow them to spend more time addressing higher-level clinical decision making. Accomplishing autonomous suturing and suture manipulation in the real world requires accurate suture thread localization and reconstruction, the process of creating a 3D shape representation of suture thread from 2D stereo camera surgical image pairs. This is a very challenging problem due to how limited pixel information is available for the threads, as well as their sensitivity to lighting and specular reflection. We present a suture thread reconstruction work that uses reliable keypoints and a Minimum Variation Spline (MVS) smoothing optimization to construct a 3D centerline from a segmented surgical image pair. This method is comparable to previous suture thread reconstruction works, with the possible benefit of increased accuracy of grasping point estimation. Our code and datasets will be available at: this https URL.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  img = {/assets/img/publication_preview/Fei_2022_ICRA_Neelay.png},
  abbr = {conference},
  color = {color_conf},
}

@article{Fei_2022_LiMingen,
  doi = {10.48550/ARXIV.2201.05753}, 
  html = {https://arxiv.org/abs/2201.05753},
  author = {LIU*, Fei and Li*, Mingen and Lu, Jingpei and Su, Entong and Yip, Michael C.},
  abstract={Simulation modeling of robots, objects, and environments is the backbone for all model-based control and learning. It is leveraged broadly across dynamic programming and model-predictive control, as well as data generation for imitation, transfer, and reinforcement learning. In addition to fidelity, key features of models in these control and learning contexts are speed, stability, and native differentiability. However, many popular simulation platforms for robotics today lack at least one of the features above. More recently, position-based dynamics (PBD) has become a very popular simulation tool for modeling complex scenes of rigid and non-rigid object interactions, due to its speed and stability, and is starting to gain significant interest in robotics for its potential use in model-based control and learning. Thus, in this paper, we present a mathematical formulation for coupling position-based dynamics (PBD) simulation and optimal robot design, model-based motion control and system identification. Our framework breaks down PBD definitions and derivations for various types of joint-based articulated rigid bodies. We present a back-propagation method with automatic differentiation, which can integrate both positional and angular geometric constraints. Our framework can critically provide the native gradient information and perform gradient-based optimization tasks. We also propose articulated joint model representations and simulation workflow for our differentiable framework. We demonstrate the capability of the framework in efficient optimal robot design, accurate trajectory torque estimation and supporting spring stiffness estimation, where we achieve minor errors. We also implement impedance control in real robots to demonstrate the potential of our differentiable framework in human-in-the-loop applications.},
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Parameter Identification and Motion Control for Articulated Rigid Body Robots Using Differentiable Position-based Dynamics},
  journal = {arXiv},
  year = {2022},
  abbr = {journal},
  color = {color_jour},
  website ={https://entongsu.github.io/differential_rigid-github.io/},
  img = {/assets/img/publication_preview/Fei_2022_LiMingen.png},
  honor = {In revision for IEEE Transactions on Robotics, TRO}
}

@article{Fei_2022_Zhaowei,
  author={Yu, Zhaowei and Schreiber, Dimitri and Liu, Fei and Yip, Michael C.},
  journal={IEEE Transactions on Mechatronics (TMECH)}, 
  title={An Underwater Remote Teleoperation Robot Arm with Rolling Diaphragm Actuation and End Effector Force Reconstruction}, 
  year={2022},
  keywords={},
  abbr = {journal},
  color = {color_jour},
  honor = {Hold on for submission with patent application},
  img = {/assets/img/publication_preview/Fei_2022_Zhaowei.png},
}

@article{Fei_2022_CatheterReconstFA,
  author={LIU, Fei and Richter, Florian and Yin, Fei and He, Chong and Girerd, Cédric and Yip, Michael C.},
  journal={IEEE Robotics and Automation Letters (RAL)}, 
  title={Continuum Robot Shape Reconstruction and Tracking from Monocular Endoscopic Image Sequences}, 
  year={2022},
  keywords={},
  abbr = {journal},
  color = {color_jour},
  honor = {To submit for internal review},
  img = {/assets/img/publication_preview/Fei_2022_CatheterReconst.png},
}

@inproceedings{Fei_2021_ICRA_Jingbin,  
  author={Huang*, Jingbin and LIU*, Fei and Richter, Florian and Yip, Michael C.},  
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},   
  title={Model-Predictive Control of Blood Suction for Surgical Hemostasis using Differentiable Fluid Simulations},   
  year={2021},  
  volume={},  
  number={},  
  pages={12380-12386},  
  abstract={Recent developments in surgical robotics have led to new advancements in the automation of surgical sub-tasks such as suturing, soft tissue manipulation, tissue tensioning and cutting. However, integration of dynamics to optimize these control policies for the variety of scenes encountered in surgery remains unsolved. Towards this effort, we investigate the integration of differentiable fluid dynamics to optimizing a suction tool’s trajectory to clear the surgical field from blood as fast as possible. The fully differentiable fluid dynamics is integrated with a novel suction model for effective model predictive control of the tool. The differentiability of the fluid model is crucial because we utilize the gradients of the fluid states with respect to the suction tool position to optimize the trajectory. Through a series of experiments, we demonstrate how, by incorporating fluid models, the trajectories generated by our method can perform as good as or better than handcrafted human-intuitive suction policies. We also show that our method is adaptable and can work in different cavity conditions while using a single handcrafted strategy fails.},  
  keywords={},  
  doi={10.1109/ICRA48506.2021.9561624}, 
  html = {https://ieeexplore.ieee.org/document/9561624},
  ISSN={2577-087X},  
  month={May},
  img = {/assets/img/publication_preview/Fei_2021_ICRA_Jingbin.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2021_Real2Sim,  
  author={LIU*, Fei and Li, Zihan and Han, Yunhai and Lu, Jingpei and Richter, Florian and Yip, Michael C.},  
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},   
  title={Real-to-Sim Registration of Deformable Soft Tissue with Position-Based Dynamics for Surgical Robot Autonomy},   
  year={2021},  
  volume={},  
  number={},  
  pages={12328-12334},  
  abstract={Autonomy in robotic surgery is very challenging in unstructured environments, especially when interacting with deformable soft tissues. The main difficulty is to generate model-based control methods that account for deformation dynamics during tissue manipulation. Previous works in vision-based perception can capture the geometric changes within the scene, however, model-based controllers integrated with dynamic properties, a more accurate and safe approach, has not been studied before. Considering the mechanic coupling between the robot and the environment, it is crucial to develop a registered, simulated dynamical model. In this work, we propose an online, continuous, real-to-sim registration method to bridge 3D visual perception with position-based dynamics (PBD) modeling of tissues. The PBD method is employed to simulate soft tissue dynamics as well as rigid tool interactions for model-based control. Meanwhile, a vision-based strategy is used to generate 3D reconstructed point cloud surfaces based on real-world manipulation, so as to register and update the simulation. To verify this real-to-sim approach, tissue experiments have been conducted on the da Vinci Research Kit. Our real-to-sim approach successfully reduces registration error online, which is especially important for safety during autonomous control. Moreover, it achieves higher accuracy in occluded areas than fusion-based reconstruction.},  
  keywords={},  
  doi={10.1109/ICRA48506.2021.9561177},  
  ISSN={2577-087X},  
  month={May},
  html = {https://ieeexplore.ieee.org/document/9561177},
  abbr = {conference},
  color = {color_conf},
  img = {/assets/img/publication_preview/Fei_2021_Real2Sim.png},
  video = {https://www.youtube.com/watch?v=hTN-ttMhpcQ}
}

@article{Fei_2021_Review,
  AUTHOR = {Mehrdad, Sarmad and LIU*, Fei and Pham, Minh Tu and Lelevé, Arnaud and Atashzar, S. Farokh},
  TITLE = {Review of Advanced Medical Telerobots},
  JOURNAL = {Applied Sciences},
  VOLUME = {11},
  YEAR = {2021},
  NUMBER = {1},
  article-NUMBER = {209},
  html = {https://www.mdpi.com/2076-3417/11/1/209},
  ISSN = {2076-3417},
  ABSTRACT = {The advent of telerobotic systems has revolutionized various aspects of the industry and human life. This technology is designed to augment human sensorimotor capabilities to extend them beyond natural competence. Classic examples are space and underwater applications when distance and access are the two major physical barriers to be combated with this technology. In modern examples, telerobotic systems have been used in several clinical applications, including teleoperated surgery and telerehabilitation. In this regard, there has been a significant amount of research and development due to the major benefits in terms of medical outcomes. Recently telerobotic systems are combined with advanced artificial intelligence modules to better share the agency with the operator and open new doors of medical automation. In this review paper, we have provided a comprehensive analysis of the literature considering various topologies of telerobotic systems in the medical domain while shedding light on different levels of autonomy for this technology, starting from direct control, going up to command-tracking autonomous telerobots. Existing challenges, including instrumentation, transparency, autonomy, stochastic communication delays, and stability, in addition to the current direction of research related to benefit in telemedicine and medical automation, and future vision of this technology, are discussed in this review paper.},
  DOI = {10.3390/app11010209},
  abbr = {journal},
  color = {color_jour},
  img = {/assets/img/publication_preview/Fei_2021_Review.png}
}

@article{Fei_2021_RAL_BloodSuction,
  author={Richter, Florian and Shen, Shihao and LIU, Fei and Huang, Jingbin and Funk, Emily K. and Orosco, Ryan K. and Yip, Michael C.},
  journal={IEEE Robotics and Automation Letters (RAL)}, 
  title={Autonomous Robotic Suction to Clear the Surgical Field for Hemostasis Using Image-Based Blood Flow Detection}, 
  year={2021},
  volume={6},
  number={2},
  pages={1383-1390},
  abstract={Autonomous robotic surgery has seen significant progression over the last decade with the aims of reducing surgeon fatigue, improving procedural consistency, and perhaps one day take over surgery itself. However, automation has not been applied to the critical surgical task of controlling tissue and blood vessel bleeding-known as hemostasis. The task of hemostasis covers a spectrum of bleeding sources and a range of blood velocity, trajectory, and volume. In an extreme case, an un-controlled blood vessel fills the surgical field with flowing blood. In this work, we present the first, automated solution for hemostasis through development of a novel probabilistic blood flow detection algorithm and a trajectory generation technique that guides autonomous suction tools towards pooling blood. The blood flow detection algorithm is tested in both simulated scenes and in a real-life trauma scenario involving a hemorrhage that occurred during thyroidectomy. The complete solution is tested in a physical lab setting with the da Vinci Research Kit (dVRK) and a simulated surgical cavity for blood to flow through. The results show that our automated solution has accurate detection, a fast reaction time, and effective removal of the flowing blood. Therefore, the proposed methods are powerful tools to clearing the surgical field which can be followed by either a surgeon or future robotic automation developments to close the vessel rupture.},
  keywords={},
  doi={10.1109/LRA.2021.3056057},
  ISSN={2377-3766},
  month={April},
  html={https://ieeexplore.ieee.org/document/9343724},
  url={https://ieeexplore.ieee.org/document/9343724},
  video = {https://www.youtube.com/watch?v=X_UPhL_TjTI},
  abbr = {journal},
  color = {color_jour},
  honor = {Best Paper Finalist Award at ICRA},
  img = {/assets/img/publication_preview/Fei_2021_RAL_BloodSuction.png},
}

@article{Fei_2020_Robotica, 
  title={An Energy-Based Approach for n-d.o.f. Passive Dual-User Haptic Training Systems}, 
  volume={38}, 
  DOI={10.1017/S0263574719001309}, 
  abstract = {This paper introduces a new controller for dual-user training systems, designed by way of an energy based approach. Dual-user training systems are useful for supervised hands-on training when a trainer shows the right gestures to a trainee and where the forces to apply on the tools are difficult to dose. An energy shared control (ESC) based architecture is proposed, based on an intrinsically passive authority sharing mechanism which is enhanced to provide a full force feedback to both users. As this enhancement may violate the natural passivity of the system, a passivity controller is introduced. A task based comparative study with two other dual-user schemes (Complementary Linear Combination (CLC) and Masters Correspondence with Environment Transfer (MECT) from is conducted, which reveals analogous performances. Real-time experiments demonstrate good tracking performances.},
  number={7}, 
  journal={Robotica}, 
  publisher={Cambridge University Press}, 
  author={LIU, Fei and Licona, Angel Ricardo and Lelevé, Arnaud and Eberard, Damien and Pham, Minh Tu and Redarce, Tanneguy}, 
  year={2020}, 
  html = {https://www.cambridge.org/core/journals/robotica/article/abs/an-energybased-approach-for-ndof-passive-dualuser-haptic-training-systems/80D42C872561E397B90F160ACD65A2F3},
  pages={1155–1175},
  abbr = {journal},
  color = {color_jour},
  img = {/assets/img/publication_preview/Fei_2020_Robotica.png}
}

@article{Fei_2020_Angel,
  author = {Licona, Angel and LIU, Fei and Pinzon, David and Torabi, Ali and Boulanger, Pierre and Leleve, Arnaud and Moreau, Richard and Pham, Minh and Tavakoli, Mahdi},
  year = {2020},
  month = {01},
  pages = {183-214},
  title = {Applications of Haptics in Medicine},
  journal = {Haptic Interfaces for Accessibility, Health, and Enhanced Quality of Life},
  abstract = {Touch is one of the most important sensory inputs during the performance of surgery. However, the literature on kinesthetic and tactile feedback both called haptics in surgical training remains rudimentary. This rudimentary knowledge is partial since that haptic feedback is difficult to describe, as well as record and playback. This chapter aims at focusing on the use of haptics in the training of medical staff and also as a complementary tool for robotized and remote procedures. It provides an overview of the various available technologies to perform haptic feedback and details on how haptic guidance can enhance surgical skill acquisition. A critical review of available haptic interfaces vis-a-vis medical interventions to be performed is provided. The chapter ends with an illustration merging the advantages of usual supervised hands-on training and the ones offered by computer-based training: dual-user training simulators.},
  isbn = {978-3-030-34229-6},
  doi = {10.1007/978-3-030-34230-2_7},
  html = {https://link.springer.com/chapter/10.1007/978-3-030-34230-2_7},
  abbr = {journal},
  color = {color_jour},
  img = {/assets/img/publication_preview/Fei_2020_Angel.png}
}


@inproceedings{Fei_2020_IROS_HanYunhai,
  doi = {10.48550/ARXIV.2010.13936},
  html = {https://arxiv.org/abs/2010.13936},
  author = {Han, Yunhai and LIU, Fei and Yip, Michael C.},
  keywords = {Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A 2D Surgical Simulation Framework for Tool-Tissue Interaction},
  booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) Workshop},
  abstract = {The control and task automation of robotic surgical system is very challenging, especially in soft tissue manipulation, due to the unpredictable deformations. Thus, an accurate simulator of soft tissues with the ability of interacting with robot manipulators is necessary. In this work, we propose a novel 2D simulation framework for tool-tissue interaction. This framework continuously tracks the motion of manipulator and simulates the tissue deformation in presence of collision detection. The deformation energy can be computed for the control and planning task.},
  year = {2020}, 
  copyright = {arXiv.org perpetual, non-exclusive license},
  img = {/assets/img/publication_preview/Fei_2020_IROS_HanYunhai.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2020_IROS_Jacob,  
  author={Johnson, Jacob J. and Li, Linjun and LIU, Fei and Qureshi, Ahmed H. and Yip, Michael C.},  
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},   
  title={Dynamically Constrained Motion Planning Networks for Non-Holonomic Robots},   
  year={2020},  
  volume={},  
  number={},  
  pages={6937-6943},  
  abstract={Reliable real-time planning for robots is essential in today's rapidly expanding automated ecosystem. In such environments, traditional methods that plan by relaxing constraints become unreliable or slow-down for kinematically constrained robots. This paper describes the algorithm Dynamic Motion Planning Networks (Dynamic MPNet), an extension to Motion Planning Networks, for non-holonomic robots that address the challenge of real-time motion planning using a neural planning approach. We propose modifications to the training and planning networks that make it possible for real-time planning while improving the data efficiency of training and trained models' generalizability. We evaluate our model in simulation for planning tasks for a non-holonomic robot. We also demonstrate experimental results for an indoor navigation task using a Dubins car.},  
  keywords={},  
  doi={10.1109/IROS45743.2020.9341283},  
  ISSN={2153-0866},  
  month={Oct},
  html = {https://ieeexplore.ieee.org/document/9341283},
  img = {/assets/img/publication_preview/Fei_2020_IROS_Jacob.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2019_ICMCE_Angel,
  author = {Licona R., Angel R. and LIU, Fei and Lelev\'{e}, Arnaud and Pham, Minh Tu},
  title = {Collaborative Hands-on Training on Haptic Simulators},
  year = {2019},
  isbn = {9781450365925},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  html = {https://doi.org/10.1145/3332305.3332318},
  doi = {10.1145/3332305.3332318},
  abstract = {Medical trainees are required to acquire sufficient skills before touching a real patient. Nowadays, haptic simulators provide an effective solution but they do not facilitate an active supervision by a trainer who should show the right gestures in terms of motions and forces to apply, in the simulated environment. Dual user training systems aim at this purpose. Even though they permit a cooperative training, they generally dot not enable efficient demonstration/evaluation modes where the user who observes the person performing a manipulation is also able to feel the interaction forces, not only the motion. We earlier introduced the Energy Shared Control (ESC) architecture aiming at providing the latter function. It is modeled with the Port Hamiltonian framework and it embeds a Time Domain Passivity Controller, to compose a one degree-of-freedom (dof) dual-user haptic system for hands-on training. In this paper, we extend it to three dof with three identical haptic devices. Experiments bring information about its performance.},
  booktitle = {Proceedings of the 2019 3rd International Conference on Virtual and Augmented Reality Simulations},
  pages = {39-45},
  numpages = {7},
  keywords = {Haptics, Training Systems, Dual User Teleoperation},
  location = {Perth, WN, Australia},
  series = {ICVARS '19},
  img = {/assets/img/publication_preview/Fei_2019_ICMCE_Angel.png},
  abbr = {conference},
  color = {color_conf},
}

@article{Fei_2016_PhDthesis,
  TITLE = {{Dual-user Haptic Training System}},
  AUTHOR = {LIU, Fei},
  journal={Ph.D. Thesis, INSA de Lyon},
  URL = {https://tel.archives-ouvertes.fr/tel-01514992},
  SCHOOL = {INSA de Lyon},
  YEAR = {2016},
  MONTH = {Sep},
  abstract={More particularly in the medical field, gesture quality is primordial. Professionals have to follow hands-on trainings to acquire a sufficient level of skills in the call of duty. For a decade, computer based simulators have helped the learners in numerous learnings, but these simulations still have to be associated with hands-on trainings on manikins, animals or cadavers, even if they do not always provide a sufficient level of realism and they are costly in the long term. Therefore, their training period has to finish on real patients, which is risky. Haptic simulators (furnishing an effort feeling) are becoming a more appropriated solution as they can reproduce realist efforts applied by organs onto the tools and they can provide countless prerecorded use cases. However, learning alone on a simulator is not always efficient compared to a fellowship training (or supervised training) where the instructor and the trainee manipulate together the same tools. Thus, this study introduces an haptic system for supervised hands-on training: the instructor and the trainee interoperate through their own haptic interface. They collaborate either with a real tool dived into a real environment (the tool is handled by a robotic arm), or with a virtual tool/environment. An energetic approach, using in particular the port-Hamiltonian modelling, has been used to ensure the stability and the robustness of the system. This system has been designed and validated experimentally on a one degree of freedom haptic interface. A comparative study with two other dual-user haptic systems (in simulation) showed the interest of this new architecture for hands-on training. In order to use this system when both users are away from each other, this study proposes some enhancements to cope with constant communication time delays, but they are not optimized yet.},
  KEYWORDS = {Haptics ; Simulation ; Fellowship Training ; Hands-on Training ; Dual-User System ; Passivity ; Comparative Study ; Communication Delay ; Port-Hamiltonian Modelling ; Haptique ;  Simulateur ;  Apprentissage supervis{\'e} ;  Dual-user ;  Passivit{\'e} ;  {\'E}tude comparative ;  Retards de transmission ;  Syst{\`e}me {\`a} ports hamiltoniens},
  pdf = {https://tel.archives-ouvertes.fr/tel-01514992/file/these%20Fei%20Liu%20version%20finale.pdf},
  html = {https://tel.archives-ouvertes.fr/tel-01514992},
  abbr = {others},
  color = {color_others},
  img = {/assets/img/publication_preview/Fei_2016_PhDthesis.png}
}

@inproceedings{Fei_2016_IROS,  
  author={LIU, Fei and Lelevé, Arnaud and Eberard, Damien and Redarce, Tanneguy},  
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},   
  title={An energy based approach for passive dual-user haptic training systems},   
  year={2016},  
  volume={},  
  number={},  
  pages={5246-5251},  
  abstract={This paper introduces a new controller for dual-user training systems, designed by way of an energy based approach. Dual-user training systems are useful for supervised hands-on training when a trainer shows the right gestures to a trainee and where the forces to apply on the tools are difficult to dose. An energy shared control (ESC) based architecture is proposed, based on an intrinsically passive authority sharing mechanism which is enhanced to provide a full force feedback to both users. As this enhancement may violate the natural passivity of the system, a passivity controller is introduced. A task based comparative study with two other dual-user schemes (Complementary Linear Combination (CLC) and Masters Correspondence with Environment Transfer (MECT) from is conducted, which reveals analogous performances. Real-time experiments demonstrate good tracking performances.},  
  keywords={},  
  doi={10.1109/IROS.2016.7759771},  
  html = {https://ieeexplore.ieee.org/document/7759771},
  ISSN={2153-0866},  
  month={Oct},
  img = {/assets/img/publication_preview/Fei_2016_IROS.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2015_EMBC,  
  author={LIU, Fei and Lelevé, Arnaud and Eberard, Damien and Redarce, Tanneguy},  
  booktitle={2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  title={A dual-user teleoperation system with Online Authority Adjustment for haptic training},   
  year={2015},  
  volume={},  
  number={},  
  pages={1168-1171},  
  abstract={This paper introduces a dual-user teleoperation system for hands-on medical training. A shared control based architecture is presented for authority management. In this structure, the combination of control signals is obtained using a dominance factor. Its main improvement is Online Authority Adjustment (OAA): the authority can be adjusted manually/automatically during the training progress. Experimental results are provided to validate the performances of the system.},  
  keywords={},  
  doi={10.1109/EMBC.2015.7318574},  
  html = {https://ieeexplore.ieee.org/document/7318574},
  ISSN={1558-4615},  
  month={Aug},
  img = {/assets/img/publication_preview/Fei_2015_EMBC.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2015_MESROB,
  author = {LIU, Fei and Leleve, Arnaud and Eberard, Damien and Redarce, Tanneguy},
  year = {2015},
  month = {07},
  pages = {},
  booktitle = {International Conference New Trends in Medical and Service Robots (MESROB)},
  title = {A Dual-User Teleoperation System with Adaptive Authority Adjustment for Haptic Training},
  abstract = {This paper presents a shared control based dual-user teleoperation haptic training system. The main contribution is an Adaptive Authority Adjustment (AAA). The authority is determined on-line according to the trainee’s behavior performance. An evaluation method is introduced based on an adaptive virtual boundary, which results into a time-varing dominance factor. An overruling function is set upstream to solve some specific cases. The system is modeled and controled in port-Hamiltonian form for passivity preserving. Experiments are conducted for validation.},
  isbn = {978-3-319-30673-5},
  doi = {10.1007/978-3-319-30674-2_13},
  html = {https://link.springer.com/chapter/10.1007/978-3-319-30674-2_13},
  img = {/assets/img/publication_preview/Fei_2015_MESROB.png},
  abbr = {conference},
  color = {color_conf},
}

@inproceedings{Fei_2012_IARC,
  author = {LIU, Fei and Yinan, Sang and Jie, He and Jie, Fan and Ruichao, Li and Xiongyi, Cui and Haoyu, Li and Jie, Chen},
  year = {2012},
  month = {},
  pages = {},
  title = {Northwestern Polytechnical University Team Entry for the 2012 AUVSI International Aerial Robotics Competition, International Aerial Robotics Competition (IARC) Symposium},
  isbn = {},
  doi = {},
  booktitle = {2012 Proceedings of International Aerial Robotics Competition (IARC)},
  abstract = {The Icarus-UAV project stresses on building an autonomous air vehicle in confined environment with relatively low cost and simple structure. The vehicle is based on a 4-rotor flight, with an FPGA as the central processing unit and transfers all necessary data to the remote workstation. The vehicle plays a role as a data collector and command executor thus avoiding extra computation unit for the vehicle. A SLAM algorithm is used for navigation with the help of Laser-3D environment remodeling unit. A smart coding pattern enables the Icarus-UAV team to program at a more abstract level for specific mission. These features enable the Icarus-UAV to execute the 6th mission of the International Aerial Robotics Competition.},
  html = {http://www.aerialroboticscompetition.org/assets/downloads/2012SymposiumPapers/2012NPU.pdf},
  img = {/assets/img/publication_preview/Fei_2012_IARC.png},
  abbr = {others},
  color = {color_others},
}
