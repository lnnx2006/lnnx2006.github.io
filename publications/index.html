<!DOCTYPE html>
<html lang="en">

<!-- Head -->

<head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5X8J72JD36"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-5X8J72JD36');

    setTimeout("gtag('event', 'adjusted bounce rate', {'event_label':'more than 15 sec'})", 30000); 
  </script>

  <!-- <script type="text/javascript"> -->
  <!-- var _gaq = _gaq || []; -->
  <!-- _gaq.push(['_setAccount', 'UA-XXXXXXX-1']); -->
  <!-- _gaq.push(['_trackPageview']); -->
  <!-- setTimeout("_gaq.push(['_trackEvent', '15_seconds', 'read'])", 15000); -->
  <!-- (function () { -->
  <!-- var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; -->
  <!-- ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; -->
  <!-- var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); -->
  <!-- })(); -->
  <!-- </script> --><!-- Metadata, OpenGraph and Schema.org -->


    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Fei  LIU | Publications</title>
    <meta name="author" content="Fei  LIU" />
    <meta name="description" content="" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


<!-- Bootstrap & MDB -->
<!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous"> -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" /> -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"
    rel="stylesheet" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css"
    crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css"
    integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css"
    integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css"
    href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet"
    href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->

<!-- Favicon.io -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png">
<link rel="manifest" href="/assets/favicon/site.webmanifest">

<!-- Styles -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://lnnx2006.github.io/publications/">

<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', '');
  </script>
</head>

<!-- Body -->

<body
  class="fixed-top-nav ">

  <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://lnnx2006.github.io/"><span class="font-weight-bold">Fei </span> LIU</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!--<li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>-->
              
              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">About</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/research/">Research</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/mentorship/">Mentorship</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching</a>
              </li>
              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

  <!-- Content -->
  <div class="container mt-5">
    <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->

<p style="font-family:courier;color:#E96357">* denotes equal contribution.</p>

<script>
function filterSubject(filter) {
  var list = document.getElementById("publicationList");
  var rows = list.getElementsByClassName("row");
  
  // Loop through all rows, hide those which don't match the selected filter
  for (i = 0; i < rows.length; i++) {
    var abbr = rows[i].getElementsByClassName("classification")[0];
    if (abbr) {
      var txtValue = abbr.textContent || abbr.innerText;
      // console.log(abbr, txtValue);
      if (txtValue.indexOf(filter) > -1) {
        rows[i].style.display = "";
      } else {
        rows[i].style.display = "none";
      }
    }
  }
  
  // Loop through all sections, hide those which are empty
  var years = list.getElementsByClassName("year");
  for (i = 0; i < years.length; i++) {
    var count = 0;
    for (j = 0; j < rows.length; j++) {
	  var section_tag = rows[j].getElementsByClassName("section-tag")[0];
	  if (section_tag.textContent == years[i].textContent && rows[j].style.display == "") { count++; }
	}
	if (count != 0) {
	  years[i].style.display = "";
	} else {
	  years[i].style.display = "none";
	}
  }
}
</script>

<!-- This is a list of my publications in reverse-chronological order.  -->
<!-- You can use the buttons below to filter according to the type of publication. -->

<!-- <center>
<abbr class="badge badge-dark" onclick="filterSubject('')" style="cursor: pointer;">all</abbr>&ensp;
<abbr class="badge badge-light" onclick="filterSubject('journal')" style="cursor: pointer;">journal</abbr>&ensp;
<abbr class="badge badge-success" onclick="filterSubject('conference')" style="cursor: pointer;">conference</abbr>&ensp;
<abbr class="badge badge-info" onclick="filterSubject('others')" style="cursor: pointer;">others</abbr>
</center>  -->

<div id="publicationList" class="publications">
  <h2 class="year">2024</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2024</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2024_RSS_ActiveJiggle.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2024_RSS_ActiveJiggle" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">JIGGLE: An Active Sensing Framework for Boundary Parameters Estimation in Deformable Surgical Environments</div>

      <!-- Honor -->
      
      <span class="honor">(Accepted)</span>
      

      <!-- Author -->
      <div class="author">Anonymous Under Review
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In Robotics: Science and Systems</em> 2024
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://drive.google.com/file/d/1y7cKRWafvDliGGdLDfNCh0gbbNRqLep1/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Surgical automation can improve the accessibility and consistency of life-saving procedures. Most surgeries require separating layers of tissue to access the surgical site, and suturing to re-attach incisions. These tasks involve deformable manipulation to safely identify and alter tissue attachment (boundary) topology. Due to poor visual acuity and frequent occlusions, surgeons tend to carefully manipulate the tissue in ways that enable inference of the tissue’s  attachment points without causing unsafe tearing. In a similar fashion, we propose JIGGLE, a framework for estimation and interactive sensing of unknown boundary parameters in deformable surgical environments. This framework has two key components: (1) a probabilistic estimation to identify the current attachment points, achieved by integrating a differentiable soft-body simulator with an extended Kalman filter (EKF), and (2) an optimization-based active control pipeline that generates actions to maximize information gain of the tissue attachments, while simultaneously minimizing safety costs. The robustness of our estimation approach is demonstrated through experiments with real animal tissue, where we infer sutured attachment points using stereo endoscope observations. We also demonstrate the capabilities of our method in handling complex topological changes such as cutting and suturing.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2024</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2024_ICRA_Real2Sim.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2024_ICRA_Real2Sim" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Real-to-Sim Deformable Object Manipulation: Optimizing Physics Models with Residual Mappings for Robotic Surgery</div>

      <!-- Honor -->
      
      <span class="honor">(Accepted)</span>
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU*</em> -->
        <em><strong><span style="color: #256D85">Fei LIU*</span></strong></em>, Xiao Liang*, Yutong Zhang, Yuelei Li, Shan Lin and Michael Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In IEEE International Conference on Robotics and Automation (ICRA)</em> 2024
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://arxiv.org/abs/2309.11656" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Accurate deformable object manipulation (DOM) is essential for achieving autonomy in robotic surgery, where soft tissues are being displaced, stretched, and dissected. Many DOM methods can be powered by simulation, which ensures realistic deformation by adhering to the governing physical constraints and allowing for model prediction and control. However, real soft objects in robotic surgery, such as membranes and soft tissues, have complex, anisotropic physical parameters that a simulation with simple initialization from cameras may not fully capture. To use the simulation techniques in real surgical tasks, the "real-to-sim" gap needs to be properly compensated. In this work, we propose an online, adaptive parameter tuning approach for simulation optimization that (1) bridges the real-to-sim gap between a physics simulation and observations obtained 3D perceptions through estimating a residual mapping and (2) optimizes its stiffness parameters online. Our method ensures a small residual gap between the simulation and observation and improves the simulation’s predictive capabilities. The effectiveness of the proposed mechanism is evaluated in the manipulation of both a thin-shell and volumetric tissue, representative of most tissue scenarios. This work contributes to the advancement of simulation-based deformable tissue manipulation and holds potential for improving surgical autonomy.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2024</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2024_ICRA_Cloth.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2024_ICRA_Cloth" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Achieving Autonomous Cloth Manipulation with Optimal Control via Differentiable Physics-Aware Regularization and Safety Constraints</div>

      <!-- Honor -->
      
      <span class="honor">(Accepted)</span>
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU*</em> -->
        <em><strong><span style="color: #256D85">Fei LIU*</span></strong></em>, Yutong Zhang*, Xiao Liang and Michael Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In IEEE International Conference on Robotics and Automation (ICRA)</em> 2024
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://arxiv.org/abs/2309.11655" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Cloth manipulation is a category of deformable object manipulation of great interest to the robotics community, from applications of automated laundry-folding and home organizing and cleaning to textiles and flexible manufacturing. Despite the desire for automated cloth manipulation, the thin-shell dynamics and under-actuation nature of cloth present significant challenges for robots to effectively interact with them. Many recent works omit explicit modeling in favor of learning-based methods that may yield control policies directly. However, these methods require large training sets that must be collected and curated. In this regard, we create a framework for differentiable modeling of cloth dynamics leveraging an Extended Position-based Dynamics (XPBD) algorithm. Together with the desired control objective, physics-aware regularization terms are designed for better results, including trajectory smoothness and elastic potential energy. In addition, safety constraints, such as avoiding obstacles, can be specified using signed distance functions (SDFs). We formulate the cloth manipulation task with safety constraints as a constrained optimization problem, which can be effectively solved by mainstream gradient-based optimizers thanks to the end-to-end differentiability of our framework. Finally, we assess the proposed framework for manipulation tasks with various safety thresholds and demonstrate the feasibility of result trajectories on a surgical robot. The effects of the regularization terms are analyzed in an additional ablation study.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2024</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2024_ICRA_Tool.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2024_ICRA_Tool" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Robust Surgical Tool Tracking with Pixel-based Probabilities for Projected Geometric Primitives</div>

      <!-- Honor -->
      
      <span class="honor">(Accepted)</span>
      

      <!-- Author -->
      <div class="author">Christopher D’Ambrosia, Florian Richter, Zih-Yun Chiu, Nikhil Shinde, 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Henrik Christensen and Michael Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In IEEE International Conference on Robotics and Automation (ICRA)</em> 2024
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://drive.google.com/file/d/1A9T2xYztqSiWgz51bBID_3xQ_cUjUbuU" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Controlling robotic manipulators via visual feedback requires a known coordinate frame transformation between the robot and the camera. Uncertainties in mechanical systems as well as camera calibration create errors in this coordinate frame transformation. These errors result in poor localization of robotic manipulators and create a significant challenge for applications that rely on precise interactions between manipulators and the environment. In this work, we estimate the camera-to-base transform and joint angle measurement errors for surgical robotic tools using an image based insertion-shaft detection algorithm and probabilistic models. We apply our proposed approach in both a structured environment as well as an unstructured environment and measure to demonstrate the efficacy of our methods.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2024</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2024_ICRA_SuPerPM.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2024_ICRA_SuPerPM" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">SuPerPM: A Large Deformation-Robust Surgical Perception Framework Based on Deep Point Matching Learned from Physical Constrained Simulation Data</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">Shan Lin, Albert Miao, Ali Alabiad, 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Kaiyuan Wang, Jingpei Lu, Florian Richter and Michael Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In </em> 2024
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://arxiv.org/abs/2309.13863" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Manipulation of tissue with surgical tools often results in large deformations that current methods in tracking and reconstructing algorithms have not effectively addressed. A major source of tracking errors during large deformations stems from wrong data association between observed sensor measurements with previously tracked scene. To mitigate this issue, we present a surgical perception framework, SuPerPM, that leverages learning-based non-rigid point cloud matching for data association, thus accommodating larger deformations. The learning models typically require training data with ground truth point cloud correspondences, which is challenging or even impractical to collect in surgical environments. Thus, for tuning the learning model, we gather endoscopic data of soft tissue being manipulated by a surgical robot and then establish correspondences between point clouds at different time points to serve as ground truth. This was achieved by employing a position-based dynamics (PBD) simulation to ensure that the correspondences adhered to physical constraints. The proposed framework is demonstrated on several challenging surgical datasets that are characterized by large deformations, achieving superior performance over state-of-the-art surgical scene tracking algorithms.</p>
      </div>
    </div>
  </div>
</li>
</ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2023</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2022_SuEntong.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2023_SuEntong" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Robotic Manipulation of Deformable Rope-like Objects Using Differentiable Compliant Position-based Dynamics</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU*</em> -->
        <em><strong><span style="color: #256D85">Fei LIU*</span></strong></em>, Entong Su*, Jingpei Lu, Mingen Li and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>IEEE Robotics and Automation (RAL)</em> 2023
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/10093017" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
        <a href="https://entongsu.github.io/differential_rope-github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Robot manipulation of rope-like objects is an interesting problem that has some critical applications, such as autonomous robotic suturing. Solving for and controlling rope is difficult due to the complexity of rope physics and the challenge of building fast and accurate models of deformable materials. While more data-driven approaches have become more popular for finding controllers that learn to do a single task, there is still a strong motivation for a model-based method that could be used to solve a large variety of optimization problems. Towards this end, we introduced compliant, position-based dynamics (XPBD) to model rope-like objects. Using geometric constraints, the model can represent the coupling of shear/stretch and bend/twist effects. Of crucial importance is that our formulation is differentiable, which can solve parameter estimation problems and improve the matching of rope physics to real-life scenarios (i.e., the real-to-sim problem). For the generality of rope-like objects, two different solvers are proposed to handle the inextensible and extensible effects of varied material stiffness for the rope. We demonstrate our framework’s robustness and accuracy on real-to-sim experimental setups using the Baxter robot and the da Vinci research kit (DVRK). Our work leads to a new path for robotic manipulation of the deformable rope-like object taking advantage of the ready-to-use gradients.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2023</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2022_TBME.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2023_Xiao" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">ORRN: An ODE-based Recursive Registration Network for Deformable Respiratory Motion Estimation with Lung 4DCT Images</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">Xiao Liang, Shan Lin, 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Dimitri Schreiber and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>IEEE Transactions on Biomedical Engineering (TBME)</em> 2023
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/10144816" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Deformable Image Registration (DIR) plays a significant role in quantifying deformation in medical data. Recent Deep Learning methods have shown promising accuracy and speedup for registering a pair of medical images. However, in 4D (3D + time) medical data, organ motion, such as respiratory motion and heart beating, can not be effectively modeled by pair-wise methods as they were optimized for image pairs but did not consider the organ motion patterns necessary when considering 4D data. This paper presents ORRN, an Ordinary Differential Equations (ODE)-based recursive image registration network. Our network learns to estimate time-varying voxel velocities for an ODE that models deformation in 4D image data. It adopts a recursive registration strategy to progressively estimate a deformation field through ODE integration of voxel velocities. We evaluate the proposed method on two publicly available lung 4DCT datasets, DIRLab and CREATIS, for two tasks: 1) registering all images to the extreme inhale image for 3D+t deformation tracking and 2) registering extreme exhale to inhale phase images. Our method outperforms other learning-based methods in both tasks, producing the smallest Target Registration Error of 1.24mm and 1.26mm, respectively. Additionally, it produces less than 0.001% unrealistic image folding, and the computation speed is less than 1 second for each CT volume. ORRN demonstrates promising registration accuracy, deformation plausibility, and computation efficiency on group-wise and pair-wise registration tasks. It has significant implications in enabling fast and accurate respiratory motion estimation for treatment planning in radiation therapy or robot motion planning in thoracic needle insertion.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2023</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2022_ICRA_Jingpei.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2023_ICRA_Jingpei" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Image-based Pose Estimation and Shape Reconstruction for Robot Manipulators and Soft, Continuum Robots via Differentiable Rendering</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU*</em> -->
        <em><strong><span style="color: #256D85">Fei LIU*</span></strong></em>, Jingpei Lu*, Cédric Girerd and Michael Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2023 IEEE International Conference on Robotics and Automation (ICRA)</em> 2023
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/10161066" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>State estimation from measured data is crucial for robotic applications as autonomous systems rely on sensors to capture the motion and localize in the 3D world. Among sensors that are designed for measuring a robot’s pose, or for soft robots, their shape, vision sensors are favorable because they are information-rich, easy to set up, and cost-effective. With recent advancements in computer vision, deep learning-based methods no longer require markers for identifying feature points on the robot. However, learning-based methods are data-hungry and hence not suitable for soft and prototyping robots, as building such bench-marking datasets is usually infeasible. In this work, we achieve image-based robot pose estimation and shape reconstruction from camera images. Our method requires no precise robot meshes, but rather utilizes a differentiable renderer and primitive shapes. It hence can be applied to robots for which CAD models might not be available or are crude. Our parameter estimation pipeline is fully differentiable. The robot shape and pose are estimated iteratively by back-propagating the image loss to update the parameters. We demonstrate that our method of using geometrical shape primitives can achieve high accuracy in shape reconstruction for a soft continuum robot and pose estimation for a robot manipulator.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2023</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2022_ICRA_Neelay.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2023_ICRA_Neelay" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Suture Thread Spline Reconstruction from Endoscopic Images for Robotic Surgery with Reliability-driven Keypoint Detection</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">Neelay Joglekar, 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Ryan Orosco and Michael Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2023 IEEE International Conference on Robotics and Automation (ICRA)</em> 2023
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/10161539" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Automating the process of manipulating and delivering sutures during robotic surgery is a prominent problem at the frontier of surgical robotics, as automating this task can significantly reduce surgeons’ fatigue during tele-operated surgery and allow them to spend more time addressing higher-level clinical decision making. Accomplishing autonomous suturing and suture manipulation in the real world requires accurate suture thread localization and reconstruction, the process of creating a 3D shape representation of suture thread from 2D stereo camera surgical image pairs. This is a very challenging problem due to how limited pixel information is available for the threads, as well as their sensitivity to lighting and specular reflection. We present a suture thread reconstruction work that uses reliable keypoints and a Minimum Variation Spline (MVS) smoothing optimization to construct a 3D centerline from a segmented surgical image pair. This method is comparable to previous suture thread reconstruction works, with the possible benefit of increased accuracy of grasping point estimation. Our code and datasets will be available at: this https URL.</p>
      </div>
    </div>
  </div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2022</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2022_Zhaowei.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2022_Zhaowei" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">An Underwater Remote Teleoperation Robot Arm with Rolling Diaphragm Actuation and End Effector Force Reconstruction</div>

      <!-- Honor -->
      
      <span class="honor">(manuscript along with patent application, check for PDF preview)</span>
      

      <!-- Author -->
      <div class="author">Zhaowei Yu, Dimitri Schreiber, Fei Liu and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>IEEE Transactions on Mechatronics (TMECH)</em> 2022
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a href="https://drive.google.com/file/d/1WP7PegDWiNI6Glp-0dRbhA1Gj9ogs_-G" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2022</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2022_LiMingen.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2022_LiMingen" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Parameter Identification and Motion Control for Articulated Rigid Body Robots Using Differentiable Position-based Dynamics</div>

      <!-- Honor -->
      
      <span class="honor">(In revision for IEEE Transactions on Robotics, TRO)</span>
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU*</em> -->
        <em><strong><span style="color: #256D85">Fei LIU*</span></strong></em>, Mingen Li*, Jingpei Lu, Entong Su and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>arXiv</em> 2022
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://arxiv.org/abs/2201.05753" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
        <a href="https://entongsu.github.io/differential_rigid-github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Simulation modeling of robots, objects, and environments is the backbone for all model-based control and learning. It is leveraged broadly across dynamic programming and model-predictive control, as well as data generation for imitation, transfer, and reinforcement learning. In addition to fidelity, key features of models in these control and learning contexts are speed, stability, and native differentiability. However, many popular simulation platforms for robotics today lack at least one of the features above. More recently, position-based dynamics (PBD) has become a very popular simulation tool for modeling complex scenes of rigid and non-rigid object interactions, due to its speed and stability, and is starting to gain significant interest in robotics for its potential use in model-based control and learning. Thus, in this paper, we present a mathematical formulation for coupling position-based dynamics (PBD) simulation and optimal robot design, model-based motion control and system identification. Our framework breaks down PBD definitions and derivations for various types of joint-based articulated rigid bodies. We present a back-propagation method with automatic differentiation, which can integrate both positional and angular geometric constraints. Our framework can critically provide the native gradient information and perform gradient-based optimization tasks. We also propose articulated joint model representations and simulation workflow for our differentiable framework. We demonstrate the capability of the framework in efficient optimal robot design, accurate trajectory torque estimation and supporting spring stiffness estimation, where we achieve minor errors. We also implement impedance control in real robots to demonstrate the potential of our differentiable framework in human-in-the-loop applications.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2022</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2022_CatheterReconst.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2022_CatheterReconstFA" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Continuum Robot Shape Reconstruction and Tracking from Monocular Endoscopic Image Sequences</div>

      <!-- Honor -->
      
      <span class="honor">(To submit)</span>
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Florian Richter, Fei Yin, Chong He, Cédric Girerd and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>IEEE Robotics and Automation Letters (RAL)</em> 2022
      </div>

      <!-- Links/Buttons -->
      <div class="links">
      </div>

      
    </div>
  </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2021</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2021_ICRA_Jingbin.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2021_ICRA_Jingbin" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Model-Predictive Control of Blood Suction for Surgical Hemostasis using Differentiable Fluid Simulations</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU*</em> -->
        <em><strong><span style="color: #256D85">Fei LIU*</span></strong></em>, Jingbin Huang*, Florian Richter and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2021 IEEE International Conference on Robotics and Automation (ICRA)</em> May 2021
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/9561624" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Recent developments in surgical robotics have led to new advancements in the automation of surgical sub-tasks such as suturing, soft tissue manipulation, tissue tensioning and cutting. However, integration of dynamics to optimize these control policies for the variety of scenes encountered in surgery remains unsolved. Towards this effort, we investigate the integration of differentiable fluid dynamics to optimizing a suction tool’s trajectory to clear the surgical field from blood as fast as possible. The fully differentiable fluid dynamics is integrated with a novel suction model for effective model predictive control of the tool. The differentiability of the fluid model is crucial because we utilize the gradients of the fluid states with respect to the suction tool position to optimize the trajectory. Through a series of experiments, we demonstrate how, by incorporating fluid models, the trajectories generated by our method can perform as good as or better than handcrafted human-intuitive suction policies. We also show that our method is adaptable and can work in different cavity conditions while using a single handcrafted strategy fails.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2021</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2021_Real2Sim.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2021_Real2Sim" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Real-to-Sim Registration of Deformable Soft Tissue with Position-Based Dynamics for Surgical Robot Autonomy</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU*</em> -->
        <em><strong><span style="color: #256D85">Fei LIU*</span></strong></em>, Zihan Li, Yunhai Han, Jingpei Lu, Florian Richter and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2021 IEEE International Conference on Robotics and Automation (ICRA)</em> May 2021
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/9561177" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
        <a href="https://www.youtube.com/watch?v=hTN-ttMhpcQ" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Autonomy in robotic surgery is very challenging in unstructured environments, especially when interacting with deformable soft tissues. The main difficulty is to generate model-based control methods that account for deformation dynamics during tissue manipulation. Previous works in vision-based perception can capture the geometric changes within the scene, however, model-based controllers integrated with dynamic properties, a more accurate and safe approach, has not been studied before. Considering the mechanic coupling between the robot and the environment, it is crucial to develop a registered, simulated dynamical model. In this work, we propose an online, continuous, real-to-sim registration method to bridge 3D visual perception with position-based dynamics (PBD) modeling of tissues. The PBD method is employed to simulate soft tissue dynamics as well as rigid tool interactions for model-based control. Meanwhile, a vision-based strategy is used to generate 3D reconstructed point cloud surfaces based on real-world manipulation, so as to register and update the simulation. To verify this real-to-sim approach, tissue experiments have been conducted on the da Vinci Research Kit. Our real-to-sim approach successfully reduces registration error online, which is especially important for safety during autonomous control. Moreover, it achieves higher accuracy in occluded areas than fusion-based reconstruction.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2021</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2021_Review.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2021_Review" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Review of Advanced Medical Telerobots</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU*</em> -->
        <em><strong><span style="color: #256D85">Fei LIU*</span></strong></em>, Sarmad Mehrdad*, Minh Tu Pham, Arnaud Lelevé and S. Farokh Atashzar
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>Applied Sciences</em> May 2021
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://www.mdpi.com/2076-3417/11/1/209" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>The advent of telerobotic systems has revolutionized various aspects of the industry and human life. This technology is designed to augment human sensorimotor capabilities to extend them beyond natural competence. Classic examples are space and underwater applications when distance and access are the two major physical barriers to be combated with this technology. In modern examples, telerobotic systems have been used in several clinical applications, including teleoperated surgery and telerehabilitation. In this regard, there has been a significant amount of research and development due to the major benefits in terms of medical outcomes. Recently telerobotic systems are combined with advanced artificial intelligence modules to better share the agency with the operator and open new doors of medical automation. In this review paper, we have provided a comprehensive analysis of the literature considering various topologies of telerobotic systems in the medical domain while shedding light on different levels of autonomy for this technology, starting from direct control, going up to command-tracking autonomous telerobots. Existing challenges, including instrumentation, transparency, autonomy, stochastic communication delays, and stability, in addition to the current direction of research related to benefit in telemedicine and medical automation, and future vision of this technology, are discussed in this review paper.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2021</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2021_RAL_BloodSuction.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2021_RAL_BloodSuction" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Autonomous Robotic Suction to Clear the Surgical Field for Hemostasis Using Image-Based Blood Flow Detection</div>

      <!-- Honor -->
      
      <span class="honor">(Best Paper Finalist Award at ICRA)</span>
      

      <!-- Author -->
      <div class="author">Florian Richter, Shihao Shen, 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Jingbin Huang, Emily K. Funk, Ryan K. Orosco and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>IEEE Robotics and Automation Letters (RAL)</em> Apr 2021
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/9343724" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
        <a href="https://www.youtube.com/watch?v=X_UPhL_TjTI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Autonomous robotic surgery has seen significant progression over the last decade with the aims of reducing surgeon fatigue, improving procedural consistency, and perhaps one day take over surgery itself. However, automation has not been applied to the critical surgical task of controlling tissue and blood vessel bleeding-known as hemostasis. The task of hemostasis covers a spectrum of bleeding sources and a range of blood velocity, trajectory, and volume. In an extreme case, an un-controlled blood vessel fills the surgical field with flowing blood. In this work, we present the first, automated solution for hemostasis through development of a novel probabilistic blood flow detection algorithm and a trajectory generation technique that guides autonomous suction tools towards pooling blood. The blood flow detection algorithm is tested in both simulated scenes and in a real-life trauma scenario involving a hemorrhage that occurred during thyroidectomy. The complete solution is tested in a physical lab setting with the da Vinci Research Kit (dVRK) and a simulated surgical cavity for blood to flow through. The results show that our automated solution has accurate detection, a fast reaction time, and effective removal of the flowing blood. Therefore, the proposed methods are powerful tools to clearing the surgical field which can be followed by either a surgeon or future robotic automation developments to close the vessel rupture.</p>
      </div>
    </div>
  </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2020</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2020_Robotica.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2020_Robotica" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">An Energy-Based Approach for n-d.o.f. Passive Dual-User Haptic Training Systems</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Angel Ricardo Licona, Arnaud Lelevé, Damien Eberard, Minh Tu Pham and Tanneguy Redarce
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>Robotica</em> Apr 2020
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://www.cambridge.org/core/journals/robotica/article/abs/an-energybased-approach-for-ndof-passive-dualuser-haptic-training-systems/80D42C872561E397B90F160ACD65A2F3" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This paper introduces a new controller for dual-user training systems, designed by way of an energy based approach. Dual-user training systems are useful for supervised hands-on training when a trainer shows the right gestures to a trainee and where the forces to apply on the tools are difficult to dose. An energy shared control (ESC) based architecture is proposed, based on an intrinsically passive authority sharing mechanism which is enhanced to provide a full force feedback to both users. As this enhancement may violate the natural passivity of the system, a passivity controller is introduced. A task based comparative study with two other dual-user schemes (Complementary Linear Combination (CLC) and Masters Correspondence with Environment Transfer (MECT) from is conducted, which reveals analogous performances. Real-time experiments demonstrate good tracking performances.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2020</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-light"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2020_Angel.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        journal
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2020_Angel" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Applications of Haptics in Medicine</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">Angel Licona, 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, David Pinzon, Ali Torabi, Pierre Boulanger, Arnaud Leleve, Richard Moreau, Minh Pham and Mahdi Tavakoli
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>Haptic Interfaces for Accessibility, Health, and Enhanced Quality of Life</em> Jan 2020
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-34230-2_7" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Touch is one of the most important sensory inputs during the performance of surgery. However, the literature on kinesthetic and tactile feedback both called haptics in surgical training remains rudimentary. This rudimentary knowledge is partial since that haptic feedback is difficult to describe, as well as record and playback. This chapter aims at focusing on the use of haptics in the training of medical staff and also as a complementary tool for robotized and remote procedures. It provides an overview of the various available technologies to perform haptic feedback and details on how haptic guidance can enhance surgical skill acquisition. A critical review of available haptic interfaces vis-a-vis medical interventions to be performed is provided. The chapter ends with an illustration merging the advantages of usual supervised hands-on training and the ones offered by computer-based training: dual-user training simulators.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2020</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2020_IROS_HanYunhai.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2020_IROS_HanYunhai" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">A 2D Surgical Simulation Framework for Tool-Tissue Interaction</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">Yunhai Han, 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em> and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) Workshop</em> Jan 2020
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://arxiv.org/abs/2010.13936" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>The control and task automation of robotic surgical system is very challenging, especially in soft tissue manipulation, due to the unpredictable deformations. Thus, an accurate simulator of soft tissues with the ability of interacting with robot manipulators is necessary. In this work, we propose a novel 2D simulation framework for tool-tissue interaction. This framework continuously tracks the motion of manipulator and simulates the tissue deformation in presence of collision detection. The deformation energy can be computed for the control and planning task.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2020</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2020_IROS_Jacob.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2020_IROS_Jacob" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Dynamically Constrained Motion Planning Networks for Non-Holonomic Robots</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">Jacob J. Johnson, Linjun Li, 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Ahmed H. Qureshi and Michael C. Yip
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em> Oct 2020
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/9341283" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Reliable real-time planning for robots is essential in today’s rapidly expanding automated ecosystem. In such environments, traditional methods that plan by relaxing constraints become unreliable or slow-down for kinematically constrained robots. This paper describes the algorithm Dynamic Motion Planning Networks (Dynamic MPNet), an extension to Motion Planning Networks, for non-holonomic robots that address the challenge of real-time motion planning using a neural planning approach. We propose modifications to the training and planning networks that make it possible for real-time planning while improving the data efficiency of training and trained models’ generalizability. We evaluate our model in simulation for planning tasks for a non-holonomic robot. We also demonstrate experimental results for an indoor navigation task using a Dubins car.</p>
      </div>
    </div>
  </div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2019</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2019_ICMCE_Angel.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2019_ICMCE_Angel" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Collaborative Hands-on Training on Haptic Simulators</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">Angel R. Licona R., 
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Arnaud Lelevé and Minh Tu Pham
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In Proceedings of the 2019 3rd International Conference on Virtual and Augmented Reality Simulations</em> Oct 2019
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://doi.org/10.1145/3332305.3332318" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Medical trainees are required to acquire sufficient skills before touching a real patient. Nowadays, haptic simulators provide an effective solution but they do not facilitate an active supervision by a trainer who should show the right gestures in terms of motions and forces to apply, in the simulated environment. Dual user training systems aim at this purpose. Even though they permit a cooperative training, they generally dot not enable efficient demonstration/evaluation modes where the user who observes the person performing a manipulation is also able to feel the interaction forces, not only the motion. We earlier introduced the Energy Shared Control (ESC) architecture aiming at providing the latter function. It is modeled with the Port Hamiltonian framework and it embeds a Time Domain Passivity Controller, to compose a one degree-of-freedom (dof) dual-user haptic system for hands-on training. In this paper, we extend it to three dof with three identical haptic devices. Experiments bring information about its performance.</p>
      </div>
    </div>
  </div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2016</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-info"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2016_PhDthesis.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        others
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2016_PhDthesis" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Dual-user Haptic Training System</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>Ph.D. Thesis, INSA de Lyon</em> Sep 2016
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://tel.archives-ouvertes.fr/tel-01514992" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
        <a href="https://tel.archives-ouvertes.fr/tel-01514992/file/these%20Fei%20Liu%20version%20finale.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>More particularly in the medical field, gesture quality is primordial. Professionals have to follow hands-on trainings to acquire a sufficient level of skills in the call of duty. For a decade, computer based simulators have helped the learners in numerous learnings, but these simulations still have to be associated with hands-on trainings on manikins, animals or cadavers, even if they do not always provide a sufficient level of realism and they are costly in the long term. Therefore, their training period has to finish on real patients, which is risky. Haptic simulators (furnishing an effort feeling) are becoming a more appropriated solution as they can reproduce realist efforts applied by organs onto the tools and they can provide countless prerecorded use cases. However, learning alone on a simulator is not always efficient compared to a fellowship training (or supervised training) where the instructor and the trainee manipulate together the same tools. Thus, this study introduces an haptic system for supervised hands-on training: the instructor and the trainee interoperate through their own haptic interface. They collaborate either with a real tool dived into a real environment (the tool is handled by a robotic arm), or with a virtual tool/environment. An energetic approach, using in particular the port-Hamiltonian modelling, has been used to ensure the stability and the robustness of the system. This system has been designed and validated experimentally on a one degree of freedom haptic interface. A comparative study with two other dual-user haptic systems (in simulation) showed the interest of this new architecture for hands-on training. In order to use this system when both users are away from each other, this study proposes some enhancements to cope with constant communication time delays, but they are not optimized yet.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2016</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2016_IROS.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2016_IROS" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">An energy based approach for passive dual-user haptic training systems</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Arnaud Lelevé, Damien Eberard and Tanneguy Redarce
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em> Oct 2016
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/7759771" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This paper introduces a new controller for dual-user training systems, designed by way of an energy based approach. Dual-user training systems are useful for supervised hands-on training when a trainer shows the right gestures to a trainee and where the forces to apply on the tools are difficult to dose. An energy shared control (ESC) based architecture is proposed, based on an intrinsically passive authority sharing mechanism which is enhanced to provide a full force feedback to both users. As this enhancement may violate the natural passivity of the system, a passivity controller is introduced. A task based comparative study with two other dual-user schemes (Complementary Linear Combination (CLC) and Masters Correspondence with Environment Transfer (MECT) from is conducted, which reveals analogous performances. Real-time experiments demonstrate good tracking performances.</p>
      </div>
    </div>
  </div>
</li>
</ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2015</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2015_EMBC.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2015_EMBC" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">A dual-user teleoperation system with Online Authority Adjustment for haptic training</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Arnaud Lelevé, Damien Eberard and Tanneguy Redarce
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em> Aug 2015
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://ieeexplore.ieee.org/document/7318574" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This paper introduces a dual-user teleoperation system for hands-on medical training. A shared control based architecture is presented for authority management. In this structure, the combination of control signals is obtained using a dominance factor. Its main improvement is Online Authority Adjustment (OAA): the authority can be adjusted manually/automatically during the training progress. Experimental results are provided to validate the performances of the system.</p>
      </div>
    </div>
  </div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2015</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-success"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2015_MESROB.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        conference
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2015_MESROB" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">A Dual-User Teleoperation System with Adaptive Authority Adjustment for Haptic Training</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Arnaud Leleve, Damien Eberard and Tanneguy Redarce
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In International Conference New Trends in Medical and Service Robots (MESROB)</em> Jul 2015
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="https://link.springer.com/chapter/10.1007/978-3-319-30674-2_13" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This paper presents a shared control based dual-user teleoperation haptic training system. The main contribution is an Adaptive Authority Adjustment (AAA). The authority is determined on-line according to the trainee’s behavior performance. An evaluation method is introduced based on an adaptive virtual boundary, which results into a time-varing dominance factor. An overruling function is set upstream to solve some specific cases. The system is modeled and controled in port-Hamiltonian form for passivity preserving. Experiments are conducted for validation.</p>
      </div>
    </div>
  </div>
</li>
</ol>

  <h2 class="year">2012</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="section-tag" style="display: none;">2012</div>
<div class="col-sm-auto">
<!---->
      <!-- <abbr class="badge badge-info"> -->
      <!----><img src="/assets/img/publication_preview/Fei_2012_IARC.png" width="250px">
      <br>
      <br>
      <!-- Classification -->
      <!-- 
      <div class="classification">
        others
      </div>
       --><!--</abbr>-->
    </div>

    <!-- Entry bib key -->
    <div id="Fei_2012_IARC" class="col-sm-8">
      
      <!-- Title -->
      <div class="title">Northwestern Polytechnical University Team Entry for the 2012 AUVSI International Aerial Robotics Competition, International Aerial Robotics Competition (IARC) Symposium</div>

      <!-- Honor -->
      

      <!-- Author -->
      <div class="author">
        <!-- <em>Fei LIU</em> -->
        <em><strong><span style="color: #256D85">Fei LIU</span></strong></em>, Sang Yinan, He Jie, Fan Jie, Li Ruichao, Cui Xiongyi, Li Haoyu and Chen Jie
      </div>

      <!-- Journal/Book title and date -->
      <div class="periodical">
        <em>In 2012 Proceedings of International Aerial Robotics Competition (IARC)</em>  2012
      </div>

      <!-- Links/Buttons -->
      <div class="links">
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
        <a href="http://www.aerialroboticscompetition.org/assets/downloads/2012SymposiumPapers/2012NPU.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
      </div>

      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>The Icarus-UAV project stresses on building an autonomous air vehicle in confined environment with relatively low cost and simple structure. The vehicle is based on a 4-rotor flight, with an FPGA as the central processing unit and transfers all necessary data to the remote workstation. The vehicle plays a role as a data collector and command executor thus avoiding extra computation unit for the vehicle. A SLAM algorithm is used for navigation with the help of Laser-3D environment remodeling unit. A smart coding pattern enables the Icarus-UAV team to program at a more abstract level for specific mission. These features enable the Icarus-UAV to execute the 6th mission of the International Aerial Robotics Competition.</p>
      </div>
    </div>
  </div>
</li></ol>


</div>

          </article>

        </div>

  </div>

  <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Fei  LIU. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.
Last updated: September 19, 2024.
      </div>
    </footer>

  <!-- JavaScripts -->
  <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.min.js" integrity="" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

  <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
  
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

</body>

</html>
